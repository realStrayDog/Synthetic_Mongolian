{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154834,"status":"ok","timestamp":1761794488865,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"},"user_tz":240},"id":"5uqTXCSre3Y8","outputId":"1bfa2289-5da6-4400-891a-6dc5fc3f9491"},"outputs":[{"output_type":"stream","name":"stdout","text":["Installing Kraken and dependencies...\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m140.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n","torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.7.1 which is incompatible.\n","tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# Mongolian OCR Training on Google Colab\n","# Run each cell in order by clicking the play button or pressing Shift+Enter\n","\n","# ===== CELL 1: Install Dependencies =====\n","print(\"Installing Kraken and dependencies...\")\n","!pip install -q kraken pillow\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25716,"status":"ok","timestamp":1761794312087,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"},"user_tz":240},"id":"f9WLzBtlfKUU","outputId":"813d5ba0-d5de-4db5-bbbc-72961395a886"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Google Drive mounted!\n","Your files should be in /content/drive/MyDrive/\n"]}],"source":["\n","# ===== CELL 2: Mount Google Drive =====\n","from google.colab import drive\n","drive.mount('/content/drive')\n","print(\"\\nGoogle Drive mounted!\")\n","print(\"Your files should be in /content/drive/MyDrive/\")\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TbNhu7YAfL-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761794735140,"user_tz":240,"elapsed":7527,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"}},"outputId":"ea1c1e5b-3f5d-481d-db1b-c1ee87b705bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.3.1\n","  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.18.1\n","  Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting torchaudio==2.3.1\n","  Downloading torchaudio-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n","Requirement already satisfied: lightning==2.4.0 in /usr/local/lib/python3.12/dist-packages (2.4.0)\n","Collecting torchmetrics==1.4.0\n","  Downloading torchmetrics-1.4.0-py3-none-any.whl.metadata (19 kB)\n","\u001b[31mERROR: Ignored the following yanked versions: 0.1.0, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.3.1, 0.3.3, 0.3.4, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5.dev1, 0.4.5, 0.4.6, 0.4.7, 0.5.0, 0.6.2, 0.6.3, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.9.0, 0.9.2, 0.9.3, 0.9.4, 0.9.6, 0.9.7, 0.9.8, 0.9.9, 0.9.10, 0.9.11, 0.9.12, 0.9.13, 0.9.14, 0.9.15, 0.9.16, 1.0.0, 1.0.1, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.8\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 4.0.0 Requires-Python <=3.10,>=3.7; 4.1.0 Requires-Python <=3.10.99,>=3.7; 4.1.1 Requires-Python <=3.10.99,>=3.7; 4.1.2 Requires-Python <=3.10.99,>=3.7; 4.2.0 Requires-Python <=3.10.99,>=3.7; 4.3.0 Requires-Python <=3.11.99,>=3.8; 4.3.1 Requires-Python <=3.11.99,>=3.8; 4.3.10 Requires-Python <=3.11.99,>=3.8; 4.3.11 Requires-Python <=3.11.99,>=3.8; 4.3.12 Requires-Python <=3.11.99,>=3.8; 4.3.13 Requires-Python <=3.11.99,>=3.8; 4.3.2 Requires-Python <=3.11.99,>=3.8; 4.3.3 Requires-Python <=3.11.99,>=3.8; 4.3.4 Requires-Python <=3.11.99,>=3.8; 4.3.5 Requires-Python <=3.11.99,>=3.8; 4.3.6 Requires-Python <=3.11.99,>=3.8; 4.3.7 Requires-Python <=3.11.99,>=3.8; 4.3.9 Requires-Python <=3.11.99,>=3.8; 5.0.0 Requires-Python <=3.11.99,>=3.8; 5.2.0 Requires-Python <=3.11.99,>=3.8; 5.2.1 Requires-Python <=3.11.99,>=3.8; 5.2.2 Requires-Python <=3.11.99,>=3.8; 5.2.3 Requires-Python <=3.11.99,>=3.8; 5.2.4 Requires-Python <=3.11.99,>=3.8; 5.2.5 Requires-Python <=3.11.99,>=3.8; 5.2.6 Requires-Python <=3.11.99,>=3.8; 5.2.7 Requires-Python <=3.11.99,>=3.8; 5.2.8 Requires-Python <=3.11.99,>=3.8; 5.2.9 Requires-Python <=3.11.99,>=3.8\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement kraken==4.3.13 (from versions: 3.0.0.0b19, 3.0.0.0b20.dev7, 3.0.0.0b20, 3.0.0.0b21, 3.0.0.0b22, 3.0.0.0b23, 3.0.0.0b24, 3.0.0.0b25, 3.0.1, 3.0.2, 3.0.4, 3.0.6, 3.0.7, 3.0.8, 3.0.9, 3.0.13, 5.3.0, 6.0.0, 6.0.2)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for kraken==4.3.13\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# --- Fix for torch/torchvision/lightning version mismatch ---\n","!pip install --upgrade torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 lightning==2.4.0 torchmetrics==1.4.0 kraken==4.3.13\n"]},{"cell_type":"code","source":["!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 \\\n","    lightning==2.4.0 torchmetrics==1.4.0 kraken==6.0.2 --upgrade --quiet\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlzAWxMoK0OZ","executionInfo":{"status":"ok","timestamp":1761795227449,"user_tz":240,"elapsed":157689,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"}},"outputId":"3da67a0d-8e25-45de-f656-ae2dce19b870"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m750.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hnYl63TzfOCZ","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1761795240376,"user_tz":240,"elapsed":9296,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"}},"outputId":"720f3eff-2447-4b2b-f7f4-f49820a41d56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Torch: 2.4.0+cu121\n","Torchvision: 0.19.0+cu121\n"]},{"output_type":"error","ename":"AttributeError","evalue":"module 'kraken' has no attribute '__version__'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-693304099.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torchvision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kraken:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkraken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA available:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'kraken' has no attribute '__version__'"]}],"source":["import torch, torchvision, kraken\n","print(\"Torch:\", torch.__version__)\n","print(\"Torchvision:\", torchvision.__version__)\n","print(\"Kraken:\", kraken.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86520,"status":"ok","timestamp":1761786720346,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"},"user_tz":240},"id":"be7kH7E-fP7e","outputId":"7a78ed83-8109-443c-c29b-65a5a2527a15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 9429 PNG images\n","Found 9429 ground truth files\n","âœ“ All files present and matched!\n"]}],"source":["# ===== CELL 5: Verify files =====\n","import glob\n","import os\n","\n","# Check if images exist\n","os.chdir('/content')\n","images = glob.glob('/content/drive/MyDrive/synthetic_mongolian_large_images/images/*.png')\n","gt_files = glob.glob('/content/drive/MyDrive/synthetic_mongolian_large_images/images/*.gt.txt')\n","\n","print(f\"Found {len(images)} PNG images\")\n","print(f\"Found {len(gt_files)} ground truth files\")\n","\n","if len(images) != len(gt_files):\n","    print(\"WARNING: Number of images and ground truth files don't match!\")\n","else:\n","    print(\"âœ“ All files present and matched!\")\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15709,"status":"ok","timestamp":1761795316573,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"},"user_tz":240},"id":"Bvys45zPfR4g"},"outputs":[],"source":["# === CELL 6: Kraken OCR Training (Drive-safe, autosave, GPU-aware) ===\n","import os, glob, random, shutil, traceback, subprocess, re, builtins, sys, torch\n","from packaging import version\n","\n","# I/O problem\n","if hasattr(sys, \"stdout\") and hasattr(sys.stdout, \"write\"):\n","    try:\n","        sys.stdout.flush()\n","    except Exception:\n","        sys.stdout = sys.__stdout__\n","\n","# Prevent Kraken exit() crash\n","builtins.exit = lambda code=0: (_ for _ in ()).throw(SystemExit(code))\n","\n","# Check Kraken version\n","try:\n","    import kraken\n","    KRAKEN_VERSION = version.parse(kraken.__version__)\n","except Exception:\n","    KRAKEN_VERSION = version.parse(\"0.0.0\")\n","#print(f\"âœ… Detected Kraken version: {KRAKEN_VERSION}\")\n","\n","from kraken.lib.train import RecognitionModel\n","from kraken.lib import train as train_lib\n","KrakenTrainer = train_lib.KrakenTrainer\n","try:\n","    from kraken.lib import evaluate\n","    HAS_EVALUATE = True\n","except ImportError:\n","    HAS_EVALUATE = False\n","\n","\n","def compute_cer(model_path, val_path, log):\n","    cer = None\n","    val_imgs = sorted(glob.glob(os.path.join(val_path, '*.png')))\n","    if not val_imgs:\n","        log(\"No validation images found.\")\n","        return None\n","    try:\n","        if HAS_EVALUATE:\n","            res = evaluate.evaluate(model=model_path, test_data=val_imgs, device='cuda' if torch.cuda.is_available() else 'cpu')\n","            cer = res.get('char_error_rate', None)\n","        else:\n","            cmd = [\"ketos\", \"test\", \"-m\", model_path, val_path]\n","            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","            m = re.search(r\"char_error_rate[:=]\\s*([0-9.]+)\", result.stdout)\n","            if m:\n","                cer = float(m.group(1))\n","    except Exception as e:\n","        log(f\"âš ï¸ CER evaluation failed: {e}\")\n","    return cer\n","\n","\n","def train_mongolian_model(\n","    data_path,\n","    checkpoints_dir,\n","    val_split,\n","    batch_size,\n","    images_per_batch,\n","    epochs,\n","    learning_rate,\n","    keep_last_n,\n","    lag,\n","    min_epochs,\n","    quit_mode,\n","    freq,\n","    partition,\n","    load_threads,\n","):\n","    \"\"\"Main Kraken OCR training loop (fast local data + Drive checkpoints).\"\"\"\n","    os.makedirs(checkpoints_dir, exist_ok=True)\n","    log_path = os.path.join(checkpoints_dir, \"training_log.txt\")\n","    cer_log_path = os.path.join(checkpoints_dir, \"cer_log.txt\")\n","\n","    def log(msg):\n","        print(msg)\n","        with open(log_path, \"a\", encoding=\"utf-8\") as f: f.write(msg + \"\\n\")\n","\n","    def log_cer(ep, cer):\n","        with open(cer_log_path, \"a\", encoding=\"utf-8\") as f:\n","            f.write(f\"Epoch {ep}: CER={cer:.4f}\\n\")\n","\n","    try:\n","        log(\"=\"*60)\n","        log(\"TRAINING START\")\n","        log(\"=\"*60)\n","\n","        # === Verify dataset consistency ===\n","        imgs = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.png\")))\n","        total = len(imgs)\n","        gts = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.gt.txt\")))\n","        log(f\"Found {total} PNGs and {len(gts)} GTs\")\n","        if total == 0:\n","            log(\"âŒ No training images found!\"); return None\n","        if abs(total - len(gts)) > 0:\n","            log(\"âš ï¸ Mismatch between .png and .gt.txt counts\")\n","\n","        # === Validation split ===\n","        val_path = os.path.join(data_path, \"validation\")\n","        if not os.path.exists(val_path):\n","            os.makedirs(val_path, exist_ok=True)\n","            n_val = max(1, int(total * val_split))\n","            val_imgs = random.sample(imgs, n_val)\n","            for img in val_imgs:\n","                gt = img.replace(\".png\", \".gt.txt\")\n","                shutil.move(img, os.path.join(val_path, os.path.basename(img)))\n","                if os.path.exists(gt):\n","                    shutil.move(gt, os.path.join(val_path, os.path.basename(gt)))\n","            log(f\"Created validation split of {n_val} images.\")\n","            imgs = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.png\")))\n","            total = len(imgs)\n","\n","        batches = [imgs[i:i+images_per_batch] for i in range(0, total, images_per_batch)]\n","        log(f\"Split into {len(batches)} batches (â‰¤{images_per_batch} each)\")\n","\n","        # === Resume if checkpoints exist ===\n","        existing = sorted(glob.glob(os.path.join(checkpoints_dir, \"mongolian_model_epoch_*.mlmodel\")))\n","        start_epoch = 1; last_ckpt = None; best_cer = float(\"inf\")\n","        if existing:\n","            last_ckpt = existing[-1]\n","            start_epoch = int(os.path.basename(last_ckpt).split(\"_\")[-1].split(\".\")[0]) + 1\n","            log(f\"Resuming from {last_ckpt}\")\n","\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","        log(f\"ğŸ”§ Using device: {device}\")\n","\n","        # === Training Loop ===\n","        for epoch in range(start_epoch, epochs + 1):\n","            log(f\"\\n===== EPOCH {epoch}/{epochs} =====\")\n","\n","            for b, batch_imgs in enumerate(batches, start=1):\n","                log(f\"Batch {b}/{len(batches)} ({len(batch_imgs)} imgs)\")\n","\n","                model = RecognitionModel(\n","                    training_data=batch_imgs,\n","                    format_type=\"path\",\n","                    hyper_params={\n","                        \"epochs\": 1,\n","                        \"lag\": lag,\n","                        \"min_epochs\": min_epochs,\n","                        \"quit\": quit_mode,\n","                        \"freq\": freq,\n","                        \"partition\": partition,\n","                        \"lrate\": learning_rate,\n","                        \"load_threads\": load_threads,\n","                        \"batch_size\": batch_size,\n","                    },\n","                    output=\"mongolian_model_temp.mlmodel\",\n","                )\n","\n","                if last_ckpt and os.path.exists(last_ckpt):\n","                    try:\n","                        model.load(last_ckpt); log(f\"Loaded {last_ckpt}\")\n","                    except Exception as e:\n","                        log(f\"âš ï¸ load failed: {e}\")\n","\n","                trainer = KrakenTrainer(enable_progress_bar=True, enable_checkpointing=False, accelerator=device)\n","                try:\n","                    trainer.fit(model)\n","                except SystemExit:\n","                    log(\"âš ï¸ Interrupted gracefully (SystemExit).\")\n","                except Exception as e:\n","                    log(f\"âš ï¸ Training interrupted: {e}\")\n","\n","            # === Save at end of epoch ===\n","            temp_model = \"mongolian_model_temp.mlmodel\"\n","            ep_path = os.path.join(checkpoints_dir, f\"mongolian_model_epoch_{epoch:02d}.mlmodel\")\n","            if os.path.exists(temp_model):\n","                try:\n","                    shutil.copy(temp_model, ep_path)\n","                    log(f\"ğŸ’¾ Saved model checkpoint for epoch {epoch}: {ep_path}\")\n","                    last_ckpt = ep_path\n","                except Exception as e:\n","                    log(f\"âš ï¸ Could not save model: {e}\")\n","            else:\n","                log(\"âš ï¸ No temp model found to save.\")\n","\n","            cer = compute_cer(last_ckpt, val_path, log)\n","            if cer and cer < best_cer:\n","                best_cer = cer\n","                log_cer(epoch, cer)\n","                log(f\"âœ¨ New best model (CER={cer:.4f})\")\n","\n","        log(\"âœ… Training complete.\")\n","        return True\n","\n","    except Exception as e:\n","        log(f\"EXCEPTION: {e}\")\n","        log(traceback.format_exc())\n","        return None\n"]},{"cell_type":"code","source":["%%writefile train_script.py\n","# Launch training with optimized parameters for 300-DPI line images\n","\n","# Function train_mongolian_model() must already be defined by running Cell 6.\n","\n","# === Adjustable parameters ===\n","DATA_PATH        = '/content/drive/MyDrive/synthetic_mongolian_large_images'\n","CHECKPOINTS_DIR  = f\"{DATA_PATH}/checkpoints\"\n","VAL_SPLIT        = 0.05\n","BATCH_SIZE       = 8\n","IMAGES_PER_BATCH = 1000\n","EPOCHS           = 60\n","LEARNING_RATE    = 0.0003\n","KEEP_LAST_N      = 3\n","LAG              = 20\n","MIN_EPOCHS       = 1\n","QUIT_MODE        = 'never'\n","FREQ             = 1.0\n","PARTITION        = 0.9\n","LOAD_THREADS     = 4\n","# ===============================\n","\n","success = train_mongolian_model(\n","    data_path=DATA_PATH,\n","    checkpoints_dir=CHECKPOINTS_DIR,\n","    val_split=VAL_SPLIT,\n","    batch_size=BATCH_SIZE,\n","    images_per_batch=IMAGES_PER_BATCH,\n","    epochs=EPOCHS,\n","    learning_rate=LEARNING_RATE,\n","    keep_last_n=KEEP_LAST_N,\n","    lag=LAG,\n","    min_epochs=MIN_EPOCHS,\n","    quit_mode=QUIT_MODE,\n","    freq=FREQ,\n","    partition=PARTITION,\n","    load_threads=LOAD_THREADS\n",")\n","\n","if success:\n","    print(\"âœ… Training completed successfully.\")\n","else:\n","    print(\"âŒ Training failed â€” check training_log.txt and cer_log.txt.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59H4-XTVZl0M","executionInfo":{"status":"ok","timestamp":1761682361409,"user_tz":240,"elapsed":5,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"}},"outputId":"80180d84-8edd-4276-8932-78113d0be755"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting train_script.py\n"]}]},{"cell_type":"code","source":["import time, re, matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","log_path = \"/content/drive/MyDrive/synthetic_mongolian_large_images/full_training_log.txt\"\n","\n","def live_plot(log_path, refresh=30):\n","    \"\"\"Continuously read the log and display Train Loss / Val Acc / Word Acc trends.\"\"\"\n","    while True:\n","        try:\n","            with open(log_path, \"r\", errors=\"ignore\") as f:\n","                text = f.read()\n","\n","            loss = [float(x) for x in re.findall(r\"train_loss_epoch:\\s*([\\d.]+)\", text)]\n","            acc  = [float(x) for x in re.findall(r\"val_accuracy:\\s*([\\d.]+)\", text)]\n","            wacc = [float(x) for x in re.findall(r\"val_word_accuracy:\\s*([\\d.]+)\", text)]\n","\n","            clear_output(wait=True)\n","            plt.figure(figsize=(8,5))\n","            if loss: plt.plot(loss, label=\"Train Loss\", color=\"orange\")\n","            if acc:  plt.plot(acc,  label=\"Val Char Acc (%)\", color=\"blue\")\n","            if wacc: plt.plot(wacc, label=\"Val Word Acc (%)\", color=\"green\")\n","            plt.xlabel(\"Stage / Epoch\"); plt.ylabel(\"Metric Value\")\n","            plt.title(\"Kraken Training Progress (Live)\")\n","            plt.legend(); plt.grid(True)\n","            plt.show()\n","        except Exception as e:\n","            print(\"Waiting for log file...\", e)\n","        time.sleep(refresh)\n","\n","live_plot(log_path, refresh=30)\n"],"metadata":{"id":"YkXMjyBeZxSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zUWfNApfUdN"},"outputs":[],"source":["# === CELL 7: Run training safely with fast local data and Drive checkpoints ===\n","from datetime import datetime\n","import sys, os, shutil, glob\n","\n","drive_root = \"/content/drive/MyDrive/synthetic_mongolian_large_images\"\n","local_data = \"/content/data\"\n","checkpoints_dir = f\"{drive_root}/checkpoints\"\n","log_path = f\"{checkpoints_dir}/full_training_log.txt\"\n","\n","# Ensure checkpoint directory exists\n","os.makedirs(checkpoints_dir, exist_ok=True)\n","\n","# ---- Reset stdout before creating Tee ----\n","sys.stdout = sys.__stdout__\n","\n","# ---- Define a safe logger ----\n","class Tee:\n","    def __init__(self, *files):\n","        self.files = files\n","    def write(self, data):\n","        for f in self.files:\n","            try:\n","                f.write(data)\n","                f.flush()\n","            except ValueError:\n","                pass  # file already closed\n","    def flush(self):\n","        for f in self.files:\n","            try:\n","                f.flush()\n","            except ValueError:\n","                pass\n","\n","# ---- Copy data locally for fast I/O ----\n","if not os.path.exists(local_data):\n","    print(\"â³ Copying image data to /content for fast access (may take several minutes)...\")\n","    shutil.copytree(drive_root, local_data)\n","else:\n","    print(\"âœ… Using existing local data directory.\")\n","\n","# ---- Start logging ----\n","with open(log_path, \"a\", encoding=\"utf-8\") as f:\n","    tee = Tee(sys.__stdout__, f)\n","    sys.stdout = tee\n","    print(f\"\\n=== Training session started {datetime.now()} ===\\n\")\n","\n","    success = train_mongolian_model(\n","        data_path=local_data,\n","        checkpoints_dir=checkpoints_dir,\n","        val_split=0.05,\n","        batch_size=8,\n","        images_per_batch=1000,\n","        epochs=60,\n","        learning_rate=0.0003,\n","        keep_last_n=3,\n","        lag=20,\n","        min_epochs=1,\n","        quit_mode=\"never\",\n","        freq=1.0,\n","        partition=0.9,\n","        load_threads=4\n","    )\n","\n","    print(\"\\nâœ… Training completed.\" if success else \"\\nâŒ Training failed.\")\n","    print(f\"=== Training session ended {datetime.now()} ===\\n\")\n","\n","# ---- Restore normal output ----\n","sys.stdout = sys.__stdout__\n","print(\"âœ… Logging closed and stdout restored.\")\n"]},{"cell_type":"code","metadata":{"id":"ee42347c"},"source":["# Read and display the training log file\n","log_file_path = '/content/drive/MyDrive/synthetic_mongolian_large_images/training_log.txt'\n","try:\n","    with open(log_file_path, 'r') as f:\n","        log_content = f.read()\n","    print(log_content)\n","except FileNotFoundError:\n","    print(f\"Error: The file {log_file_path} was not found.\")\n","except Exception as e:\n","    print(f\"An error occurred while reading the file: {e}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# NEW CELL: Convert existing checkpoint to usable model\n","import glob\n","import os\n","\n","# Find the latest checkpoint\n","checkpoints = glob.glob('/content/drive/MyDrive/*.ckpt')\n","checkpoints.sort()\n","\n","if checkpoints:\n","    latest_ckpt = checkpoints[-1]\n","    print(f\"Found {len(checkpoints)} checkpoints\")\n","    print(f\"Latest: {latest_ckpt}\")\n","\n","    # Load the checkpoint and save as .mlmodel\n","    from kraken.lib.train import RecognitionModel\n","\n","    print(\"\\nConverting checkpoint to .mlmodel format...\")\n","    model = RecognitionModel.load_from_checkpoint(latest_ckpt)\n","    model.save('mongolian_model_epoch48.mlmodel')\n","\n","    # Copy to Drive\n","    import shutil\n","    shutil.copy('mongolian_model_epoch48.mlmodel', '/content/drive/MyDrive/mongolian_model_epoch48.mlmodel')\n","    print(\"âœ“ Model saved to: /content/drive/MyDrive/mongolian_model_epoch48.mlmodel\")\n","    print(\"\\nYou can download and use this model now!\")\n","else:\n","    print(\"No checkpoints found!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mTTCb2_AEZDu","executionInfo":{"status":"ok","timestamp":1761659175422,"user_tz":240,"elapsed":10,"user":{"displayName":"Dotno Pount","userId":"06643883993489280289"}},"outputId":"c5955c2c-1310-40fe-aca1-39f5d59599bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["No checkpoints found!\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeN2b69pfVvN"},"outputs":[],"source":["# ===== CELL 8: Test the model =====\n","# Test on a sample image\n","test_image = 'synthetic_mongolian_large_images/images/line_0500-1.png'\n","\n","print(f\"Testing model on: {test_image}\")\n","!kraken -i {test_image} output.txt segment ocr -m mongolian_model.mlmodel\n","\n","print(\"\\nGround truth:\")\n","!cat synthetic_mongolian_large_images/images/line_0500-1.gt.txt\n","\n","print(\"\\nModel prediction:\")\n","!cat output.txt\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USSa5eMpfW2A"},"outputs":[],"source":["# ===== CELL 9: Download the trained model =====\n","from google.colab import files\n","\n","print(\"Downloading trained model...\")\n","files.download('mongolian_model.mlmodel')\n","print(\"Model downloaded! You can now use it for OCR.\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJcR6Uqafcuk"},"outputs":[],"source":["# ===== CELL 10: (Optional) Save model to Google Drive =====\n","# Uncomment and run if you want to save to Drive for later use\n","\n","# import shutil\n","# shutil.copy('mongolian_model.mlmodel', '/content/drive/MyDrive/mongolian_model.mlmodel')\n","# print(\"Model saved to Google Drive!\")"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP+9wZzZiq7u6tlZ4me96XM"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}