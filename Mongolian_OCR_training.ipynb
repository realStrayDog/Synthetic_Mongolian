{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uqTXCSre3Y8"
      },
      "outputs": [],
      "source": [
        "# Mongolian OCR Training on Google Colab\n",
        "# Run each cell in order by clicking the play button or pressing Shift+Enter\n",
        "\n",
        "# ===== CELL 1: Install Dependencies =====\n",
        "print(\"Installing Kraken and dependencies...\")\n",
        "!pip install -q kraken pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9WLzBtlfKUU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ===== CELL 2: Mount Google Drive =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\nGoogle Drive mounted!\")\n",
        "print(\"Your files should be in /content/drive/MyDrive/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbNhu7YAfL-0"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 3: Upload your files =====\n",
        "# After mounting Drive, you have two options:\n",
        "# OPTION A: Upload directly to Colab (faster for this session only)\n",
        "print(\"\\nOption A: Upload files directly to Colab\")\n",
        "print(\"Run the next cell to upload a zip file of your project\")\n",
        "\n",
        "# OPTION B: Copy from Google Drive (better for repeated use)\n",
        "print(\"\\nOption B: Use files from Google Drive\")\n",
        "print(\"1. Upload your 'synthetic_mongolian' folder to Google Drive\")\n",
        "print(\"2. Update the path in Cell 5 to point to your Drive folder\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnYl63TzfOCZ"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 4: Upload ZIP file (if using Option A) =====\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"Upload your project ZIP file (should contain synthetic_mongolian folder)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the ZIP\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"Extracting {filename}...\")\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/')\n",
        "    print(f\"Extracted to /content/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be7kH7E-fP7e"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 5: Verify files =====\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Check if images exist\n",
        "os.chdir('/content')\n",
        "images = glob.glob('/content/drive/MyDrive/synthetic_mongolian/images/*.png')\n",
        "gt_files = glob.glob('/content/drive/MyDrive/synthetic_mongolian/images/*.gt.txt')\n",
        "\n",
        "print(f\"Found {len(images)} PNG images\")\n",
        "print(f\"Found {len(gt_files)} ground truth files\")\n",
        "\n",
        "if len(images) != len(gt_files):\n",
        "    print(\"WARNING: Number of images and ground truth files don't match!\")\n",
        "else:\n",
        "    print(\"✓ All files present and matched!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1QFq5MYHyfN"
      },
      "outputs": [],
      "source": [
        "# ===== DIAGNOSTIC CELL: Find your files =====\n",
        "import os\n",
        "import glob\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"SEARCHING FOR YOUR FILES...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n1. Contents of /content/:\")\n",
        "os.system('ls -la /content/')\n",
        "\n",
        "print(\"\\n2. Contents of /content/drive/MyDrive/ (first 20 items):\")\n",
        "os.system('ls -la /content/drive/MyDrive/ | head -20')\n",
        "\n",
        "print(\"\\n3. Searching for 'synthetic_mongolian' folder:\")\n",
        "os.system('find /content -name \"synthetic_mongolian\" -type d 2>/dev/null')\n",
        "os.system('find /content/drive/MyDrive -name \"synthetic_mongolian\" -type d 2>/dev/null')\n",
        "\n",
        "print(\"\\n4. Searching for PNG files:\")\n",
        "patterns = [\n",
        "    'synthetic_mongolian/images/*.png',\n",
        "    '/content/synthetic_mongolian/images/*.png',\n",
        "    '/content/drive/MyDrive/synthetic_mongolian/images/*.png',\n",
        "    '/content/drive/MyDrive/Gemini/synthetic_mongolian/images/*.png',\n",
        "]\n",
        "\n",
        "for pattern in patterns:\n",
        "    files = glob.glob(pattern)\n",
        "    print(f\"   {pattern}\")\n",
        "    print(f\"   → Found {len(files)} files\")\n",
        "\n",
        "print(\"\\n5. What's in MyDrive root?\")\n",
        "os.system('ls /content/drive/MyDrive/')\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # NEW CELL: Resize all images before training\n",
        "# import os\n",
        "# from PIL import Image\n",
        "# import glob\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# print(\"Starting image resize operation...\")\n",
        "\n",
        "# # Paths\n",
        "# original_dir = '/content/drive/MyDrive/synthetic_mongolian'\n",
        "# temp_new_dir = '/content/drive/MyDrive/synthetic_mongolian_resized'\n",
        "# backup_dir = '/content/drive/MyDrive/synthetic_mongolian_large_images'\n",
        "\n",
        "# # Create new directory\n",
        "# os.makedirs(temp_new_dir, exist_ok=True)\n",
        "# os.makedirs(os.path.join(temp_new_dir, 'images'), exist_ok=True)\n",
        "\n",
        "# # Target dimensions\n",
        "# TARGET_WIDTH = 48\n",
        "# TARGET_HEIGHT = 120\n",
        "\n",
        "# # Get all images\n",
        "# image_files = sorted(glob.glob(os.path.join(original_dir, 'images', '*.png')))\n",
        "# gt_files = sorted(glob.glob(os.path.join(original_dir, 'images', '*.gt.txt')))\n",
        "\n",
        "# print(f\"Found {len(image_files)} images to resize\")\n",
        "# print(f\"Target size: {TARGET_WIDTH}x{TARGET_HEIGHT} pixels\")\n",
        "# print(\"This will take about 10-15 minutes...\\n\")\n",
        "\n",
        "# # Resize images\n",
        "# for img_path in tqdm(image_files, desc=\"Resizing images\"):\n",
        "#     # Load image\n",
        "#     img = Image.open(img_path).convert('L')  # Grayscale\n",
        "\n",
        "#     # Resize maintaining aspect ratio\n",
        "#     original_w, original_h = img.size\n",
        "\n",
        "#     # Calculate scaling to fit within target dimensions\n",
        "#     scale_w = TARGET_WIDTH / original_w\n",
        "#     scale_h = TARGET_HEIGHT / original_h\n",
        "#     scale = min(scale_w, scale_h)\n",
        "\n",
        "#     new_w = int(original_w * scale)\n",
        "#     new_h = int(original_h * scale)\n",
        "\n",
        "#     # Resize\n",
        "#     img_resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "#     # Create canvas with target dimensions (white background)\n",
        "#     canvas = Image.new('L', (TARGET_WIDTH, TARGET_HEIGHT), 255)\n",
        "\n",
        "#     # Paste resized image centered on canvas\n",
        "#     paste_x = (TARGET_WIDTH - new_w) // 2\n",
        "#     paste_y = (TARGET_HEIGHT - new_h) // 2\n",
        "#     canvas.paste(img_resized, (paste_x, paste_y))\n",
        "\n",
        "#     # Save\n",
        "#     filename = os.path.basename(img_path)\n",
        "#     canvas.save(os.path.join(temp_new_dir, 'images', filename))\n",
        "\n",
        "# print(\"\\nCopying ground truth files...\")\n",
        "# # Copy .gt.txt files\n",
        "# for gt_path in tqdm(gt_files, desc=\"Copying GT files\"):\n",
        "#     filename = os.path.basename(gt_path)\n",
        "#     import shutil\n",
        "#     shutil.copy(gt_path, os.path.join(temp_new_dir, 'images', filename))\n",
        "\n",
        "# print(\"\\nRenaming directories...\")\n",
        "# # Rename original to backup\n",
        "# os.rename(original_dir, backup_dir)\n",
        "# print(f\"✓ Renamed {original_dir} → {backup_dir}\")\n",
        "\n",
        "# # Rename new to original\n",
        "# os.rename(temp_new_dir, original_dir)\n",
        "# print(f\"✓ Renamed {temp_new_dir} → {original_dir}\")\n",
        "\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"RESIZE COMPLETE!\")\n",
        "# print(\"=\"*60)\n",
        "# print(f\"Original large images backed up to: {backup_dir}\")\n",
        "# print(f\"Resized images now at: {original_dir}\")\n",
        "# print(f\"All {len(image_files)} images resized to {TARGET_WIDTH}×{TARGET_HEIGHT}\")\n",
        "# print(\"\\nYou can now run Cell 6 and Cell 7 with the resized images!\")\n",
        "# print(\"Training should be ~25x faster!\")"
      ],
      "metadata": {
        "id": "Y0xEmts8f4fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvys45zPfR4g"
      },
      "outputs": [],
      "source": [
        "# CELL 6 — Batchwise OCR training for Mongolian (Kraken)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import traceback\n",
        "from kraken.lib.train import RecognitionModel, KrakenTrainer\n",
        "\n",
        "def train_mongolian_model(\n",
        "    data_path='/content/drive/MyDrive/synthetic_mongolian',\n",
        "    total_epochs=50,\n",
        "    mini_batch_size=32,\n",
        "    learning_rate=0.001,\n",
        "    early_stopping_patience=10,\n",
        "    images_per_batch=2500\n",
        "):\n",
        "\n",
        "    # logging\n",
        "    log_path = os.path.join(data_path, 'training_log.txt')\n",
        "    log_file = open(log_path, 'w')\n",
        "\n",
        "    def log(msg):\n",
        "        print(msg)\n",
        "        log_file.write(msg + '\\n')\n",
        "        log_file.flush()\n",
        "\n",
        "    try:\n",
        "        log(\"=\"*60)\n",
        "        log(\"TRAINING with EPOCH-BY-EPOCH SAVING\")\n",
        "        log(\"=\"*60)\n",
        "\n",
        "        # locate all images directly in Drive\n",
        "        img_pattern = os.path.join(data_path, 'images', '*.png')\n",
        "        all_imgs = sorted(glob.glob(img_pattern))\n",
        "        if not all_imgs:\n",
        "            log(f\"ERROR: no images found at {img_pattern}\")\n",
        "            return None\n",
        "\n",
        "        total = len(all_imgs)\n",
        "        log(f\"Found {total} total training images\")\n",
        "\n",
        "        # chunk image list into batches\n",
        "        batches = [all_imgs[i:i+images_per_batch] for i in range(0, total, images_per_batch)]\n",
        "        log(f\"Processing {len(batches)} batches of up to {images_per_batch} images each\")\n",
        "\n",
        "        # Define checkpoint directory\n",
        "        checkpoints_dir = os.path.join(data_path, 'checkpoints')\n",
        "        os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "        log(f\"Checkpoints will be saved to: {checkpoints_dir}\")\n",
        "\n",
        "        # Initial model (start fresh or load latest)\n",
        "        model = None\n",
        "        latest_checkpoint = sorted(glob.glob(os.path.join(checkpoints_dir, 'mongolian_model_epoch_*.mlmodel')))\n",
        "        if latest_checkpoint:\n",
        "            model_path = latest_checkpoint[-1]\n",
        "            log(f\"Loading latest checkpoint: {model_path}\")\n",
        "            model = RecognitionModel(file=model_path)\n",
        "        else:\n",
        "            log(\"Initializing new model.\")\n",
        "\n",
        "        # training loop across epochs\n",
        "        for epoch in range(1, total_epochs + 1):\n",
        "            log(f\"\\n===== EPOCH {epoch}/{total_epochs} ====\")\n",
        "            for b, batch_imgs in enumerate(batches, start=1):\n",
        "                log(f\"\\n--- Training batch {b}/{len(batches)} ({len(batch_imgs)} images) ---\")\n",
        "\n",
        "                model = RecognitionModel(\n",
        "                    training_data=batch_imgs,\n",
        "                    format_type='path',\n",
        "                    hyper_params={\n",
        "                        'epochs': total_epochs,\n",
        "                        'lag': early_stopping_patience,\n",
        "                        'min_epochs': 10,\n",
        "                        'quit': 'dumb',\n",
        "                        'freq': 1.0,\n",
        "                        'partition': 0.9,\n",
        "                        'lrate': learning_rate,\n",
        "                        'load_threads': 2,\n",
        "                        'batch_size': mini_batch_size,\n",
        "                    },\n",
        "                    output='mongolian_model_temp.mlmodel',\n",
        "                )\n",
        "\n",
        "                trainer = KrakenTrainer(\n",
        "                    enable_progress_bar=True,\n",
        "                    enable_checkpointing=False,\n",
        "                    accelerator='auto',\n",
        "                )\n",
        "\n",
        "                trainer.fit(model)\n",
        "\n",
        "            # save after each full epoch\n",
        "            epoch_path = os.path.join(\n",
        "                data_path, f\"checkpoints/mongolian_model_epoch_{epoch:02d}.mlmodel\"\n",
        "            )\n",
        "            os.makedirs(os.path.dirname(epoch_path), exist_ok=True)\n",
        "            if os.path.exists('mongolian_model_temp.mlmodel'):\n",
        "                os.replace('mongolian_model_temp.mlmodel', epoch_path)\n",
        "                log(f\"Saved model checkpoint: {epoch_path}\")\n",
        "            else:\n",
        "                log(\"WARNING: Temporary model file not found after epoch\")\n",
        "\n",
        "        log(\"=\"*60)\n",
        "        log(\"Training complete!\")\n",
        "        log(\"=\"*60)\n",
        "        log_file.close()\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        log(\"\\n\" + \"=\"*60)\n",
        "        log(\"EXCEPTION OCCURRED:\")\n",
        "        log(\"=\"*60)\n",
        "        log(f\"{type(e).__name__}: {e}\")\n",
        "        log(traceback.format_exc())\n",
        "        log(\"=\"*60)\n",
        "        log_file.close()\n",
        "        return None\n",
        "\n",
        "print(\"Batchwise training function defined — will read/write directly to Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zUWfNApfUdN"
      },
      "outputs": [],
      "source": [
        "# CELL 7 — launch training\n",
        "success = train_mongolian_model(\n",
        "    data_path='/content/drive/MyDrive/synthetic_mongolian',\n",
        "    mini_batch_size=32,\n",
        "    total_epochs=50,              # adjust for longer runs if needed\n",
        "    images_per_batch=2500,  # Increased given smaller image size\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"Training completed successfully! Check checkpoints folder in Google Drive.\")\n",
        "else:\n",
        "    print(\"Training failed — see training_log.txt in your Drive folder for details.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===== CELL 7.5: Delete old checkpoints =====\n",
        "#old_ckpts = sorted(glob.glob(os.path.join(checkpoints_dir, \"mongolian_model_epoch_*.mlmodel\")))\n",
        "#if len(old_ckpts) > keep_last_n:\n",
        "#    for ckpt in old_ckpts[:-keep_last_n]:\n",
        "#        os.remove(ckpt)\n"
      ],
      "metadata": {
        "id": "iosiYQZmWnL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeN2b69pfVvN"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 8: Test the model =====\n",
        "# Test on a sample image\n",
        "test_image = 'synthetic_mongolian/images/line_0500-1.png'\n",
        "\n",
        "print(f\"Testing model on: {test_image}\")\n",
        "!kraken -i {test_image} output.txt segment ocr -m mongolian_model.mlmodel\n",
        "\n",
        "print(\"\\nGround truth:\")\n",
        "!cat synthetic_mongolian/images/line_0500-1.gt.txt\n",
        "\n",
        "print(\"\\nModel prediction:\")\n",
        "!cat output.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USSa5eMpfW2A"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 9: Download the trained model =====\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading trained model...\")\n",
        "files.download('mongolian_model.mlmodel')\n",
        "print(\"Model downloaded! You can now use it for OCR.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJcR6Uqafcuk"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 10: (Optional) Save model to Google Drive =====\n",
        "# Uncomment and run if you want to save to Drive for later use\n",
        "\n",
        "import shutil\n",
        "shutil.copy('mongolian_model.mlmodel', '/content/drive/MyDrive/mongolian_model.mlmodel')\n",
        "print(\"Model saved to Google Drive!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}