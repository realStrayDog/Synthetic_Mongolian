{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uqTXCSre3Y8"
      },
      "outputs": [],
      "source": [
        "# Mongolian OCR Training on Google Colab\n",
        "# Run each cell in order by clicking the play button or pressing Shift+Enter\n",
        "\n",
        "# ===== CELL 1: Install Dependencies =====\n",
        "print(\"Installing Kraken and dependencies...\")\n",
        "!pip install -q kraken pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9WLzBtlfKUU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ===== CELL 2: Mount Google Drive =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\nGoogle Drive mounted!\")\n",
        "print(\"Your files should be in /content/drive/MyDrive/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbNhu7YAfL-0"
      },
      "outputs": [],
      "source": [
        "# --- Fix for torch/torchvision/lightning version mismatch ---\n",
        "!pip install --upgrade torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 lightning==2.4.0 torchmetrics==1.4.0 kraken==4.3.13\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 \\\n",
        "    lightning==2.4.0 torchmetrics==1.4.0 kraken==6.0.2 --upgrade --quiet\n"
      ],
      "metadata": {
        "id": "IlzAWxMoK0OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnYl63TzfOCZ"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision, kraken\n",
        "print(\"Torch:\", torch.__version__)\n",
        "print(\"Torchvision:\", torchvision.__version__)\n",
        "print(\"Kraken:\", kraken.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be7kH7E-fP7e"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 5: Verify files =====\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Check if images exist\n",
        "os.chdir('/content')\n",
        "images = glob.glob('/content/drive/MyDrive/synthetic_mongolian_large_images/images/*.png')\n",
        "gt_files = glob.glob('/content/drive/MyDrive/synthetic_mongolian_large_images/images/*.gt.txt')\n",
        "\n",
        "print(f\"Found {len(images)} PNG images\")\n",
        "print(f\"Found {len(gt_files)} ground truth files\")\n",
        "\n",
        "if len(images) != len(gt_files):\n",
        "    print(\"WARNING: Number of images and ground truth files don't match!\")\n",
        "else:\n",
        "    print(\"‚úì All files present and matched!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvys45zPfR4g"
      },
      "outputs": [],
      "source": [
        "# === CELL 6: Kraken OCR Training (Drive-safe, autosave, GPU-aware) ===\n",
        "import os, glob, random, shutil, traceback, subprocess, re, builtins, sys, torch\n",
        "from packaging import version\n",
        "\n",
        "# I/O problem\n",
        "if hasattr(sys, \"stdout\") and hasattr(sys.stdout, \"write\"):\n",
        "    try:\n",
        "        sys.stdout.flush()\n",
        "    except Exception:\n",
        "        sys.stdout = sys.__stdout__\n",
        "\n",
        "# Prevent Kraken exit() crash\n",
        "builtins.exit = lambda code=0: (_ for _ in ()).throw(SystemExit(code))\n",
        "\n",
        "# Check Kraken version\n",
        "try:\n",
        "    import kraken\n",
        "    KRAKEN_VERSION = version.parse(kraken.__version__)\n",
        "except Exception:\n",
        "    KRAKEN_VERSION = version.parse(\"0.0.0\")\n",
        "#print(f\"‚úÖ Detected Kraken version: {KRAKEN_VERSION}\")\n",
        "\n",
        "from kraken.lib.train import RecognitionModel\n",
        "from kraken.lib import train as train_lib\n",
        "KrakenTrainer = train_lib.KrakenTrainer\n",
        "try:\n",
        "    from kraken.lib import evaluate\n",
        "    HAS_EVALUATE = True\n",
        "except ImportError:\n",
        "    HAS_EVALUATE = False\n",
        "\n",
        "\n",
        "def compute_cer(model_path, val_path, log):\n",
        "    cer = None\n",
        "    val_imgs = sorted(glob.glob(os.path.join(val_path, '*.png')))\n",
        "    if not val_imgs:\n",
        "        log(\"No validation images found.\")\n",
        "        return None\n",
        "    try:\n",
        "        if HAS_EVALUATE:\n",
        "            res = evaluate.evaluate(model=model_path, test_data=val_imgs, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            cer = res.get('char_error_rate', None)\n",
        "        else:\n",
        "            cmd = [\"ketos\", \"test\", \"-m\", model_path, val_path]\n",
        "            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "            m = re.search(r\"char_error_rate[:=]\\s*([0-9.]+)\", result.stdout)\n",
        "            if m:\n",
        "                cer = float(m.group(1))\n",
        "    except Exception as e:\n",
        "        log(f\"‚ö†Ô∏è CER evaluation failed: {e}\")\n",
        "    return cer\n",
        "\n",
        "\n",
        "def train_mongolian_model(\n",
        "    data_path,\n",
        "    checkpoints_dir,\n",
        "    val_split,\n",
        "    batch_size,\n",
        "    images_per_batch,\n",
        "    epochs,\n",
        "    learning_rate,\n",
        "    keep_last_n,\n",
        "    lag,\n",
        "    min_epochs,\n",
        "    quit_mode,\n",
        "    freq,\n",
        "    partition,\n",
        "    load_threads,\n",
        "):\n",
        "    \"\"\"Main Kraken OCR training loop (fast local data + Drive checkpoints).\"\"\"\n",
        "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "    log_path = os.path.join(checkpoints_dir, \"training_log.txt\")\n",
        "    cer_log_path = os.path.join(checkpoints_dir, \"cer_log.txt\")\n",
        "\n",
        "    def log(msg):\n",
        "        print(msg)\n",
        "        with open(log_path, \"a\", encoding=\"utf-8\") as f: f.write(msg + \"\\n\")\n",
        "\n",
        "    def log_cer(ep, cer):\n",
        "        with open(cer_log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"Epoch {ep}: CER={cer:.4f}\\n\")\n",
        "\n",
        "    try:\n",
        "        log(\"=\"*60)\n",
        "        log(\"TRAINING START\")\n",
        "        log(\"=\"*60)\n",
        "\n",
        "        # === Verify dataset consistency ===\n",
        "        imgs = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.png\")))\n",
        "        total = len(imgs)\n",
        "        gts = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.gt.txt\")))\n",
        "        log(f\"Found {total} PNGs and {len(gts)} GTs\")\n",
        "        if total == 0:\n",
        "            log(\"‚ùå No training images found!\"); return None\n",
        "        if abs(total - len(gts)) > 0:\n",
        "            log(\"‚ö†Ô∏è Mismatch between .png and .gt.txt counts\")\n",
        "\n",
        "        # === Validation split ===\n",
        "        val_path = os.path.join(data_path, \"validation\")\n",
        "        if not os.path.exists(val_path):\n",
        "            os.makedirs(val_path, exist_ok=True)\n",
        "            n_val = max(1, int(total * val_split))\n",
        "            val_imgs = random.sample(imgs, n_val)\n",
        "            for img in val_imgs:\n",
        "                gt = img.replace(\".png\", \".gt.txt\")\n",
        "                shutil.move(img, os.path.join(val_path, os.path.basename(img)))\n",
        "                if os.path.exists(gt):\n",
        "                    shutil.move(gt, os.path.join(val_path, os.path.basename(gt)))\n",
        "            log(f\"Created validation split of {n_val} images.\")\n",
        "            imgs = sorted(glob.glob(os.path.join(data_path, \"images\", \"*.png\")))\n",
        "            total = len(imgs)\n",
        "\n",
        "        batches = [imgs[i:i+images_per_batch] for i in range(0, total, images_per_batch)]\n",
        "        log(f\"Split into {len(batches)} batches (‚â§{images_per_batch} each)\")\n",
        "\n",
        "        # === Resume if checkpoints exist ===\n",
        "        existing = sorted(glob.glob(os.path.join(checkpoints_dir, \"mongolian_model_epoch_*.mlmodel\")))\n",
        "        start_epoch = 1; last_ckpt = None; best_cer = float(\"inf\")\n",
        "        if existing:\n",
        "            last_ckpt = existing[-1]\n",
        "            start_epoch = int(os.path.basename(last_ckpt).split(\"_\")[-1].split(\".\")[0]) + 1\n",
        "            log(f\"Resuming from {last_ckpt}\")\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        log(f\"üîß Using device: {device}\")\n",
        "\n",
        "        # === Training Loop ===\n",
        "        for epoch in range(start_epoch, epochs + 1):\n",
        "            log(f\"\\n===== EPOCH {epoch}/{epochs} =====\")\n",
        "\n",
        "            for b, batch_imgs in enumerate(batches, start=1):\n",
        "                log(f\"Batch {b}/{len(batches)} ({len(batch_imgs)} imgs)\")\n",
        "\n",
        "                model = RecognitionModel(\n",
        "                    training_data=batch_imgs,\n",
        "                    format_type=\"path\",\n",
        "                    hyper_params={\n",
        "                        \"epochs\": 1,\n",
        "                        \"lag\": lag,\n",
        "                        \"min_epochs\": min_epochs,\n",
        "                        \"quit\": quit_mode,\n",
        "                        \"freq\": freq,\n",
        "                        \"partition\": partition,\n",
        "                        \"lrate\": learning_rate,\n",
        "                        \"load_threads\": load_threads,\n",
        "                        \"batch_size\": batch_size,\n",
        "                    },\n",
        "                    output=\"mongolian_model_temp.mlmodel\",\n",
        "                )\n",
        "\n",
        "                if last_ckpt and os.path.exists(last_ckpt):\n",
        "                    try:\n",
        "                        model.load(last_ckpt); log(f\"Loaded {last_ckpt}\")\n",
        "                    except Exception as e:\n",
        "                        log(f\"‚ö†Ô∏è load failed: {e}\")\n",
        "\n",
        "                trainer = KrakenTrainer(enable_progress_bar=True, enable_checkpointing=False, accelerator=device)\n",
        "                try:\n",
        "                    trainer.fit(model)\n",
        "                except SystemExit:\n",
        "                    log(\"‚ö†Ô∏è Interrupted gracefully (SystemExit).\")\n",
        "                except Exception as e:\n",
        "                    log(f\"‚ö†Ô∏è Training interrupted: {e}\")\n",
        "\n",
        "            # === Save at end of epoch ===\n",
        "            temp_model = \"mongolian_model_temp.mlmodel\"\n",
        "            ep_path = os.path.join(checkpoints_dir, f\"mongolian_model_epoch_{epoch:02d}.mlmodel\")\n",
        "            if os.path.exists(temp_model):\n",
        "                try:\n",
        "                    shutil.copy(temp_model, ep_path)\n",
        "                    log(f\"üíæ Saved model checkpoint for epoch {epoch}: {ep_path}\")\n",
        "                    last_ckpt = ep_path\n",
        "                except Exception as e:\n",
        "                    log(f\"‚ö†Ô∏è Could not save model: {e}\")\n",
        "            else:\n",
        "                log(\"‚ö†Ô∏è No temp model found to save.\")\n",
        "\n",
        "            cer = compute_cer(last_ckpt, val_path, log)\n",
        "            if cer and cer < best_cer:\n",
        "                best_cer = cer\n",
        "                log_cer(epoch, cer)\n",
        "                log(f\"‚ú® New best model (CER={cer:.4f})\")\n",
        "\n",
        "        log(\"‚úÖ Training complete.\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        log(f\"EXCEPTION: {e}\")\n",
        "        log(traceback.format_exc())\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_script.py\n",
        "# Launch training with optimized parameters for 300-DPI line images\n",
        "\n",
        "# Function train_mongolian_model() must already be defined by running Cell 6.\n",
        "\n",
        "# === Adjustable parameters ===\n",
        "DATA_PATH        = '/content/drive/MyDrive/synthetic_mongolian_large_images'\n",
        "CHECKPOINTS_DIR  = f\"{DATA_PATH}/checkpoints\"\n",
        "VAL_SPLIT        = 0.05\n",
        "BATCH_SIZE       = 8\n",
        "IMAGES_PER_BATCH = 1000\n",
        "EPOCHS           = 60\n",
        "LEARNING_RATE    = 0.0003\n",
        "KEEP_LAST_N      = 3\n",
        "LAG              = 20\n",
        "MIN_EPOCHS       = 1\n",
        "QUIT_MODE        = 'never'\n",
        "FREQ             = 1.0\n",
        "PARTITION        = 0.9\n",
        "LOAD_THREADS     = 4\n",
        "# ===============================\n",
        "\n",
        "success = train_mongolian_model(\n",
        "    data_path=DATA_PATH,\n",
        "    checkpoints_dir=CHECKPOINTS_DIR,\n",
        "    val_split=VAL_SPLIT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    images_per_batch=IMAGES_PER_BATCH,\n",
        "    epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    keep_last_n=KEEP_LAST_N,\n",
        "    lag=LAG,\n",
        "    min_epochs=MIN_EPOCHS,\n",
        "    quit_mode=QUIT_MODE,\n",
        "    freq=FREQ,\n",
        "    partition=PARTITION,\n",
        "    load_threads=LOAD_THREADS\n",
        ")\n",
        "\n",
        "if success:\n",
        "    print(\"‚úÖ Training completed successfully.\")\n",
        "else:\n",
        "    print(\"‚ùå Training failed ‚Äî check training_log.txt and cer_log.txt.\")\n"
      ],
      "metadata": {
        "id": "59H4-XTVZl0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time, re, matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "log_path = \"/content/drive/MyDrive/synthetic_mongolian_large_images/full_training_log.txt\"\n",
        "\n",
        "def live_plot(log_path, refresh=30):\n",
        "    \"\"\"Continuously read the log and display Train Loss / Val Acc / Word Acc trends.\"\"\"\n",
        "    while True:\n",
        "        try:\n",
        "            with open(log_path, \"r\", errors=\"ignore\") as f:\n",
        "                text = f.read()\n",
        "\n",
        "            loss = [float(x) for x in re.findall(r\"train_loss_epoch:\\s*([\\d.]+)\", text)]\n",
        "            acc  = [float(x) for x in re.findall(r\"val_accuracy:\\s*([\\d.]+)\", text)]\n",
        "            wacc = [float(x) for x in re.findall(r\"val_word_accuracy:\\s*([\\d.]+)\", text)]\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            plt.figure(figsize=(8,5))\n",
        "            if loss: plt.plot(loss, label=\"Train Loss\", color=\"orange\")\n",
        "            if acc:  plt.plot(acc,  label=\"Val Char Acc (%)\", color=\"blue\")\n",
        "            if wacc: plt.plot(wacc, label=\"Val Word Acc (%)\", color=\"green\")\n",
        "            plt.xlabel(\"Stage / Epoch\"); plt.ylabel(\"Metric Value\")\n",
        "            plt.title(\"Kraken Training Progress (Live)\")\n",
        "            plt.legend(); plt.grid(True)\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(\"Waiting for log file...\", e)\n",
        "        time.sleep(refresh)\n",
        "\n",
        "live_plot(log_path, refresh=30)\n"
      ],
      "metadata": {
        "id": "YkXMjyBeZxSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zUWfNApfUdN"
      },
      "outputs": [],
      "source": [
        "# === CELL 7: Run training safely with fast local data and Drive checkpoints ===\n",
        "from datetime import datetime\n",
        "import sys, os, shutil, glob\n",
        "\n",
        "drive_root = \"/content/drive/MyDrive/synthetic_mongolian_large_images\"\n",
        "local_data = \"/content/data\"\n",
        "checkpoints_dir = f\"{drive_root}/checkpoints\"\n",
        "log_path = f\"{checkpoints_dir}/full_training_log.txt\"\n",
        "\n",
        "# Ensure checkpoint directory exists\n",
        "os.makedirs(checkpoints_dir, exist_ok=True)\n",
        "\n",
        "# ---- Reset stdout before creating Tee ----\n",
        "sys.stdout = sys.__stdout__\n",
        "\n",
        "# ---- Define a safe logger ----\n",
        "class Tee:\n",
        "    def __init__(self, *files):\n",
        "        self.files = files\n",
        "    def write(self, data):\n",
        "        for f in self.files:\n",
        "            try:\n",
        "                f.write(data)\n",
        "                f.flush()\n",
        "            except ValueError:\n",
        "                pass  # file already closed\n",
        "    def flush(self):\n",
        "        for f in self.files:\n",
        "            try:\n",
        "                f.flush()\n",
        "            except ValueError:\n",
        "                pass\n",
        "\n",
        "# ---- Copy data locally for fast I/O ----\n",
        "if not os.path.exists(local_data):\n",
        "    print(\"‚è≥ Copying image data to /content for fast access (may take several minutes)...\")\n",
        "    shutil.copytree(drive_root, local_data)\n",
        "else:\n",
        "    print(\"‚úÖ Using existing local data directory.\")\n",
        "\n",
        "# ---- Start logging ----\n",
        "with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
        "    tee = Tee(sys.__stdout__, f)\n",
        "    sys.stdout = tee\n",
        "    print(f\"\\n=== Training session started {datetime.now()} ===\\n\")\n",
        "\n",
        "    success = train_mongolian_model(\n",
        "        data_path=local_data,\n",
        "        checkpoints_dir=checkpoints_dir,\n",
        "        val_split=0.05,\n",
        "        batch_size=8,\n",
        "        images_per_batch=1000,\n",
        "        epochs=60,\n",
        "        learning_rate=0.0003,\n",
        "        keep_last_n=3,\n",
        "        lag=20,\n",
        "        min_epochs=1,\n",
        "        quit_mode=\"never\",\n",
        "        freq=1.0,\n",
        "        partition=0.9,\n",
        "        load_threads=4\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ Training completed.\" if success else \"\\n‚ùå Training failed.\")\n",
        "    print(f\"=== Training session ended {datetime.now()} ===\\n\")\n",
        "\n",
        "# ---- Restore normal output ----\n",
        "sys.stdout = sys.__stdout__\n",
        "print(\"‚úÖ Logging closed and stdout restored.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee42347c"
      },
      "source": [
        "# Read and display the training log file\n",
        "log_file_path = '/content/drive/MyDrive/synthetic_mongolian_large_images/training_log.txt'\n",
        "try:\n",
        "    with open(log_file_path, 'r') as f:\n",
        "        log_content = f.read()\n",
        "    print(log_content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {log_file_path} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the file: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW CELL: Convert existing checkpoint to usable model\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Find the latest checkpoint\n",
        "checkpoints = glob.glob('/content/drive/MyDrive/*.ckpt')\n",
        "checkpoints.sort()\n",
        "\n",
        "if checkpoints:\n",
        "    latest_ckpt = checkpoints[-1]\n",
        "    print(f\"Found {len(checkpoints)} checkpoints\")\n",
        "    print(f\"Latest: {latest_ckpt}\")\n",
        "\n",
        "    # Load the checkpoint and save as .mlmodel\n",
        "    from kraken.lib.train import RecognitionModel\n",
        "\n",
        "    print(\"\\nConverting checkpoint to .mlmodel format...\")\n",
        "    model = RecognitionModel.load_from_checkpoint(latest_ckpt)\n",
        "    model.save('mongolian_model_epoch48.mlmodel')\n",
        "\n",
        "    # Copy to Drive\n",
        "    import shutil\n",
        "    shutil.copy('mongolian_model_epoch48.mlmodel', '/content/drive/MyDrive/mongolian_model_epoch48.mlmodel')\n",
        "    print(\"‚úì Model saved to: /content/drive/MyDrive/mongolian_model_epoch48.mlmodel\")\n",
        "    print(\"\\nYou can download and use this model now!\")\n",
        "else:\n",
        "    print(\"No checkpoints found!\")"
      ],
      "metadata": {
        "id": "mTTCb2_AEZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeN2b69pfVvN"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 8: Test the model =====\n",
        "# Test on a sample image\n",
        "test_image = 'synthetic_mongolian_large_images/images/line_0500-1.png'\n",
        "\n",
        "print(f\"Testing model on: {test_image}\")\n",
        "!kraken -i {test_image} output.txt segment ocr -m mongolian_model.mlmodel\n",
        "\n",
        "print(\"\\nGround truth:\")\n",
        "!cat synthetic_mongolian_large_images/images/line_0500-1.gt.txt\n",
        "\n",
        "print(\"\\nModel prediction:\")\n",
        "!cat output.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USSa5eMpfW2A"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 9: Download the trained model =====\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Downloading trained model...\")\n",
        "files.download('mongolian_model.mlmodel')\n",
        "print(\"Model downloaded! You can now use it for OCR.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJcR6Uqafcuk"
      },
      "outputs": [],
      "source": [
        "# ===== CELL 10: (Optional) Save model to Google Drive =====\n",
        "# Uncomment and run if you want to save to Drive for later use\n",
        "\n",
        "# import shutil\n",
        "# shutil.copy('mongolian_model.mlmodel', '/content/drive/MyDrive/mongolian_model.mlmodel')\n",
        "# print(\"Model saved to Google Drive!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
